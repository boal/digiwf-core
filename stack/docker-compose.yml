# Use this only in dev environments. It's not intended for production usage.
version: '3.9'
services:
  optimize:
    # docker login registry.camunda.cloud
    image: registry.camunda.cloud/optimize-ee/optimize:3.12.0
    container_name: digiwf-optimize
    hostname: optimize
    depends_on:
      - elasticsearch
    ports:
      - '18090:8090'
      - '18091:8091'
    env_file:
      - local-docker.env
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      JAVA_OPTS: '-Xms1g -Xmx1g -XX:MaxMetaspaceSize=256m'
      OPTIMIZE_ELASTICSEARCH_HOST: 'elasticsearch'
      OPTIMIZE_ELASTICSEARCH_HTTP_PORT: '9200'
    volumes:
      - './optimize/environment-config.yaml:/optimize/config/environment-config.yaml'
      - '../digiwf-libs/digiwf-optimize-plugins/target/digiwf-optimize-plugins-jar-with-dependencies.jar:/optimize/plugin/digiwf-plugins.jar'
    networks:
      - local-keycloak
      - internal
    profiles:
      - optimize

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.1
    container_name: digiwf-elasticsearch
    hostname: elasticsearch
    ports:
      - '9200:9200'
      - '9300:9300'
    environment:
      - bootstrap.memory_lock=true
      - discovery.type=single-node
      - xpack.security.enabled=false
      - cluster.name=elasticsearch
      - action.auto_create_index=false
      # allow running with low disk space
      - cluster.routing.allocation.disk.threshold_enabled=false
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m'
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=1024mb
      - cluster.routing.allocation.disk.watermark.high=512mb
      - cluster.routing.allocation.disk.watermark.flood_stage=256mb
    networks:
      - local-keycloak
    profiles:
      - optimize

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - '22181:2181'
    healthcheck:
      test: nc -z localhost 2181 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - internal
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - '9092:9092'
      - '29092:29092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - internal

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - '8089:8080'
    depends_on:
      - kafka
      - zookeeper
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - internal


  init-kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka
    env_file:
      - local-docker.env
    entrypoint: [ '/bin/bash', '-c' ]
    networks:
      - internal
    command: |
      "      
      # blocks until kafka is reachable
      echo -e 'Currently available topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
      
      echo -e 'Creating kafka topics...'
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_TASKS} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_DATA_ENTRIES} --replication-factor 1 --partitions 1
      
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_COCREATION_DEPLOY} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_COCREATION} --replication-factor 1 --partitions 1
      
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_ENGINE} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_ENGINE_DLQ} --replication-factor 1 --partitions 1
      
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR_DLQ} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR_INCIDENT} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR_BPMNERROR} --replication-factor 1 --partitions 1
      
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_EMAIL_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_S3_CLIENT_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_S3_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_S3_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_COSYS_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_ALW_INTEGRATION} --replication-factor 1 --partitions 1     
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_MUCS_DMS_INTEGRATION} --replication-factor 1 --partitions 1  
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_ALW_DMS_INTEGRATION} --replication-factor 1 --partitions 1  
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_TICKET_INTEGRATION} --replication-factor 1 --partitions 1  

      echo -e 'Resulting topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
      "

  minio:
    image: quay.io/minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: Test1234
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - ./minio:/data
    networks:
      - internal

  init-minio:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
        mc config host add minio http://minio:9000 minio Test1234;
        mc mb minio/digiwf-bucket;
        exit 0;
      "
    networks:
      - internal

  mailpit:
    container_name: digiwf-mailpit
    image: axllent/mailpit:latest
    ports:
      - '1025:1025' # smtp server
      - '8025:8025' # ui
    networks:
      - internal

  digiwf-gateway:
    image: itatm/digiwf-gateway:dev
    depends_on:
      init-keycloak:
        condition: service_completed_successfully
    env_file:
      - local-docker.env
    ports:
      - "8083:8083"
    environment:
      #
      # profile specific configuration
      #
      SPRING_PROFILES_ACTIVE: "local, docker" #possible values: local or  (local, docker) # add profile 'docker' if you want to run the engine and frontend in docker, add local when you want to run the engine and frontend outside of docker
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - internal

  # enable the tasklist with --profile tasklist if you don't want to run it locally. Then access via http://localhost:8083
  digiwf-tasklist:
    image: itatm/digiwf-tasklist:dev
    ports:
      - "8091:8080"
    profiles:
      - tasklist-frontend
    networks:
      - internal

  digiwf-webcomponent:
    image: itatm/digiwf-webcomponent:dev
    ports:
      - "8092:8080"
    profiles:
      - webcomponent
    networks:
      - internal
  #
  # Local keycloak. To work properly, you need to change your local hosts file and add an alias to your
  # `127.0.0.1 localhost` line to look like this: `127.0.0.1 localhost keycloak`.
  # On Mac/Linux it is located in `/etc/hosts` on Win `C:\Windows\System32\Drivers\etc\hosts`
  #
  keycloak:
    container_name: digiwf-keycloak
    image: ${KEYCLOAK_IMAGE:-quay.io/keycloak/keycloak:20.0.3}
    depends_on:
      - postgres-keycloak
    ports:
      - '8080:8080'
    command: 'start-dev --http-relative-path /auth'
    environment:
      KC_HOSTNAME: keycloak # this hostname must be resolved to 127.0.0.1 locally. Add it to your hosts file.
      KC_HOSTNAME_STRICT: 'false'
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres-keycloak:5432/keycloak
      KC_DB_USERNAME: keycloak-user
      KC_DB_PASSWORD: keycloak-secret
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    networks:
      - local-keycloak
      - internal

  init-keycloak:
    image: klg71/keycloakmigration:0.2.55
    depends_on:
      - keycloak
    env_file:
      - './local-docker.env'
    environment:
      ADMIN_USER: admin
      ADMIN_PASSWORD: admin
      BASEURL: http://keycloak:8080/auth # uses internal docker network to access the keycloak via its back channel port
      WAIT_FOR_KEYCLOAK: 'true'
      KEYCLOAK_CHANGELOG: /migration/keycloak-changelog.yml
    volumes:
      - './keycloak:/migration'
    networks:
      - local-keycloak

  pgadmin:
    image: dpage/pgadmin4:8.2
    ports:
      - "8888:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: digiwf@muenchen.de
      PGADMIN_DEFAULT_PASSWORD: test
    networks:
      - internal

  postgres-engine:
    image: postgres:13.2
    container_name: digiwf-postgres-engine
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: enginedb
    ports:
      - '25433:5432'
    networks:
      - internal

  postgres-tasklist:
    image: postgres:13.2
    container_name: digiwf-postgres-tasklist
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: tasklistdb
    ports:
      - '25432:5432'
    networks:
      - internal

  postgres-s3:
    image: postgres:13.2
    container_name: digiwf-postgres-s3
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: s3db
    ports:
      - '25434:5432'
    networks:
      - internal

  postgres-keycloak:
    image: postgres:13.2
    container_name: digiwf-postgres-keycloak
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak-user
      POSTGRES_PASSWORD: keycloak-secret
    networks:
      - local-keycloak

  # enable the cocreation deployment with --profile cocreation if you don't want to run it locally
  digiwf-cocreation-deployment:
    image: itatm/digiwf-cocreation-deployment-service:dev
    ports:
      - "9010:8080"
    depends_on:
      init-keycloak:
        condition: service_completed_successfully
    profiles:
      - cocreation
    env_file:
      - './local-docker.env'
    environment:
      SPRING_PROFILES_ACTIVE: "local"
      ENGINE_HOST: "http://host.docker.internal"
      #      ENGINE_SERVER_PORT: "39146" # already defined in local-docker.env
      SSO_BASE_URL: "http://host.docker.internal:8080/auth"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - internal

networks:
  local-keycloak:
  internal:
